{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing notebook - ashwat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4945, 25)\n"
     ]
    }
   ],
   "source": [
    "# import data from CSV file\n",
    "raw_data = pd.read_csv('NFLCombineData.csv')\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Players' Data Missing for --> \b fortyyd : 191\n"
     ]
    }
   ],
   "source": [
    "# quick test, to see how many values are missing for a specific parameter\n",
    "parameter = 'fortyyd'\n",
    "raw_data_no_outlier = raw_data.loc[raw_data[parameter] > 0]\n",
    "print(\"Number of Players' Data Missing for -->\", \"\\b\", parameter, \":\", raw_data.shape[0]-raw_data_no_outlier.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combining positions based on related characterisitcs into groupings (6 classes)\n",
    "    # 0: Running Backs: RB, FB\n",
    "    # 1: Pass Catchers: WR, TE\n",
    "    # 2: Defensive Backs: FS, SS, CB\n",
    "    # 3: Lineman: OT, OG, OC, C, NT, DT, DE, LS \n",
    "    # 4: Linebackers: ILB, OLB\n",
    "    # 5: Quarterback + Special Team: QB, P, K\n",
    "    \n",
    "# create dictionary of metrics corresponding to index in data\n",
    "pos_dict = {'year': 0, 'name': 1, 'firstname': 2, 'lastname': 3, 'position': 4, 'heightfeet': 5, \n",
    "            'heightinches': 6, 'heightinchestotal': 7, 'weight': 8, 'arms': 9, 'hands': 10,\n",
    "            'fortyyd': 11, 'twentyyd': 12, 'tenyd': 13, 'twentyss': 14, 'threecone': 15, \n",
    "            'vertical': 16, 'broad': 17, 'bench': 18, 'round': 19, 'college': 20, \n",
    "            'pickround': 21, 'picktotal': 22, 'wonderlic': 23, 'nflgrade': 24}\n",
    "\n",
    "# extract all players (stored by position) from raw_data\n",
    "rb = (raw_data.loc[raw_data['position'] == 'RB']).to_numpy()\n",
    "fb = (raw_data.loc[raw_data['position'] == 'FB']).to_numpy()\n",
    "wr = (raw_data.loc[raw_data['position'] == 'WR']).to_numpy()\n",
    "te = (raw_data.loc[raw_data['position'] == 'TE']).to_numpy()\n",
    "fs = (raw_data.loc[raw_data['position'] == 'FS']).to_numpy()\n",
    "ss = (raw_data.loc[raw_data['position'] == 'SS']).to_numpy()\n",
    "cb = (raw_data.loc[raw_data['position'] == 'CB']).to_numpy()\n",
    "ot = (raw_data.loc[raw_data['position'] == 'OT']).to_numpy()\n",
    "og = (raw_data.loc[raw_data['position'] == 'OG']).to_numpy()\n",
    "oc = (raw_data.loc[raw_data['position'] == 'OC']).to_numpy()\n",
    "c = (raw_data.loc[raw_data['position'] == 'C']).to_numpy()\n",
    "nt = (raw_data.loc[raw_data['position'] == 'NT']).to_numpy()\n",
    "dt = (raw_data.loc[raw_data['position'] == 'DT']).to_numpy()\n",
    "de = (raw_data.loc[raw_data['position'] == 'DE']).to_numpy()\n",
    "ls = (raw_data.loc[raw_data['position'] == 'LS']).to_numpy()\n",
    "ilb = (raw_data.loc[raw_data['position'] == 'ILB']).to_numpy()\n",
    "olb = (raw_data.loc[raw_data['position'] == 'OLB']).to_numpy()\n",
    "qb = (raw_data.loc[raw_data['position'] == 'QB']).to_numpy()\n",
    "p = (raw_data.loc[raw_data['position'] == 'P']).to_numpy()\n",
    "k = (raw_data.loc[raw_data['position'] == 'K']).to_numpy()\n",
    "\n",
    "# concatenate similar positions based on the classification of groups (detailed above)\n",
    "run_back = np.concatenate((rb, fb))\n",
    "pass_catch = np.concatenate((wr, te))\n",
    "defense_back = np.concatenate((fs, ss, cb))\n",
    "linemen = np.concatenate((ot, og, oc, c, nt, dt, de, ls))\n",
    "lineback = np.concatenate((ilb, olb))\n",
    "quarterback_special = np.concatenate((qb, p, k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4945\n",
      "4\n",
      "4945\n"
     ]
    }
   ],
   "source": [
    "# initialize arrays to store data\n",
    "data_players = []\n",
    "pos_index = []\n",
    "\n",
    "# *** INPUT HERE, WHICH PARAMETERS TO EXTRACT AND TRAIN ON ***\n",
    "parameters = ['weight', 'heightinchestotal', 'broad', 'fortyyd']\n",
    "\n",
    "# 0: Running Backs: RB, FB\n",
    "for i in range(len(run_back)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(run_back[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(0)\n",
    "    \n",
    "# 1: Pass Catchers: WR, TE\n",
    "for i in range(len(pass_catch)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(pass_catch[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(1)\n",
    "    \n",
    "# 2: Defensive Backs: FS, SS, CB\n",
    "for i in range(len(defense_back)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(defense_back[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(2)\n",
    "    \n",
    "# 3: Lineman: OT, OG, OC, C, NT, DT, DE, LS \n",
    "for i in range(len(linemen)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(linemen[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(3)\n",
    "    \n",
    "# 4: Linebackers: ILB, OLB\n",
    "for i in range(len(lineback)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(lineback[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(4)\n",
    "    \n",
    "# 5: Quarterback + Special Team: QB, P, K\n",
    "for i in range(len(quarterback_special)):\n",
    "    rowArr = []\n",
    "    for j in range(len(parameters)):\n",
    "        rowArr.append(quarterback_special[i][pos_dict.get(parameters[j])])\n",
    "    data_players.append(np.array(rowArr))\n",
    "    pos_index.append(5)\n",
    "    \n",
    "# convert from list to array\n",
    "data_players = np.array(data_players)\n",
    "\n",
    "# one-hot encode outputs for classifcation\n",
    "pos_index = np.array(pos_index)\n",
    "pos_index = to_categorical(pos_index, 6)\n",
    "\n",
    "print(len(data_players)) # --> 4945, all players metrics pulled\n",
    "print(len(data_players[0])) # --> 4, all parameters considered\n",
    "print(len(pos_index)) # --> 4945, all players' groupings labeled\n",
    "\n",
    "# ALL GOOD SO FAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=6, input_shape=(len(parameters),), activation='softmax')) # 3 output units, because 3 classes\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x=data_players, y=pos_index, validation_split = 0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### IGNORE BELOW THIS POINT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my positions: QB P K FS SS\n",
    "qb_data = raw_data.loc[raw_data['position'] == 'QB'] # 304 entries\n",
    "p_data = raw_data.loc[raw_data['position'] == 'P'] # 12 entries\n",
    "k_data = raw_data.loc[raw_data['position'] == 'K'] # 9 entries\n",
    "fs_data = raw_data.loc[raw_data['position'] == 'FS'] # 211 entries\n",
    "ss_data = raw_data.loc[raw_data['position'] == 'SS'] # 184 entries\n",
    "\n",
    "\n",
    "\n",
    "# # good metric, consistent data for all positions\n",
    "# sns.violinplot(x=qb_data[\"heightinchestotal\"])\n",
    "# sns.violinplot(x=fs_data[\"heightinchestotal\"])\n",
    "# sns.violinplot(x=ss_data[\"heightinchestotal\"])\n",
    "\n",
    "# # poor metric, large amount of absent data\n",
    "# sns.violinplot(x=qb_data[\"threecone\"])\n",
    "# sns.violinplot(x=fs_data[\"threecone\"])\n",
    "# sns.violinplot(x=ss_data[\"threecone\"])\n",
    "\n",
    "# # fairly good metric, somewhat consistent data for all positions (few null)\n",
    "# sns.violinplot(x=qb_data[\"broad\"])\n",
    "# sns.violinplot(x=fs_data[\"broad\"])\n",
    "# sns.violinplot(x=ss_data[\"broad\"])\n",
    "\n",
    "# # bad metric, no data for QB players\n",
    "# sns.violinplot(x=qb_data[\"bench\"])\n",
    "# sns.violinplot(x=fs_data[\"bench\"])\n",
    "# sns.violinplot(x=ss_data[\"bench\"])\n",
    "\n",
    "# # potentially good metric, consistent data for all positions (but might not have correlation)\n",
    "# sns.violinplot(x=qb_data[\"weight\"])\n",
    "# sns.violinplot(x=fs_data[\"weight\"])\n",
    "# sns.violinplot(x=ss_data[\"weight\"])\n",
    "\n",
    "\n",
    "\n",
    "raw_data_no_outlier = raw_data.loc[raw_data['vertical'] > 0]\n",
    "raw_data_no_outlier = raw_data.loc[raw_data['threecone'] > 0]\n",
    "raw_data_no_outlier = raw_data.loc[raw_data['broad'] > 0]\n",
    "raw_data_no_outlier = raw_data.loc[raw_data['bench'] > 0]\n",
    "raw_data_no_outlier = raw_data.loc[raw_data['round'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# positions = list(raw_data['position'].unique())\n",
    "\n",
    "# positions.remove('P')\n",
    "# positions.remove('K')\n",
    "\n",
    "positions = list(['QB', 'FS', 'SS'])\n",
    "\n",
    "pos_index = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qb_data = raw_data.loc[raw_data['position'] == 'QB']\n",
    "fs_data = raw_data.loc[raw_data['position'] == 'FS']\n",
    "ss_data = raw_data.loc[raw_data['position'] == 'SS']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = raw_data\n",
    "dataPlayers = []\n",
    "pos_index = []\n",
    "\n",
    "# print(type(qb_data))\n",
    "\n",
    "parameters = ['weight', 'heightinchestotal', 'broad']\n",
    "\n",
    "qb_weight = qb_data['weight'].to_numpy()\n",
    "qb_height = qb_data['heightinchestotal'].to_numpy()\n",
    "qb_broad = qb_data['broad'].to_numpy()\n",
    "\n",
    "fs_weight = fs_data['weight'].to_numpy()\n",
    "fs_height = fs_data['heightinchestotal'].to_numpy()\n",
    "fs_broad = fs_data['broad'].to_numpy()\n",
    "\n",
    "ss_weight = ss_data['weight'].to_numpy()\n",
    "ss_height = ss_data['heightinchestotal'].to_numpy()\n",
    "ss_broad = ss_data['broad'].to_numpy()\n",
    "\n",
    "for i in range(len(qb_data)):\n",
    "    dataPlayers.append([qb_weight[i], qb_height[i], qb_broad[i]])\n",
    "    pos_index.append(0)\n",
    "for i in range(len(fs_data)):\n",
    "    dataPlayers.append([fs_weight[i], fs_height[i], fs_broad[i]])\n",
    "    pos_index.append(1)\n",
    "for i in range(len(ss_data)):\n",
    "    dataPlayers.append([ss_weight[i], ss_height[i], ss_broad[i]])\n",
    "    pos_index.append(2)\n",
    "    \n",
    "pos_index = np.array(pos_index)\n",
    "pos_cat = to_categorical(pos_index, 3)\n",
    "\n",
    "dataPlayers = np.array(dataPlayers)\n",
    "\n",
    "# print(dataQB)\n",
    "# print(pos_index)\n",
    "# print(qb_data['weight'])\n",
    "# print(qb_data['heightinchestotal'])\n",
    "# print(qb_data['broad'])\n",
    "\n",
    "# print(dataPlayers[0])\n",
    "\n",
    "print(pos_cat.shape)\n",
    "print(dataPlayers.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=3, input_shape=(3,), activation='softmax')) # 3 output units, because 3 classes\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "h = model.fit(x=dataPlayers, y=pos_cat, batch_size=50, validation_split = 0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy'])\n",
    "plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.array([dataPlayers[0]])\n",
    "\n",
    "prediction = model.predict_classes(point)\n",
    "print(\"Predicted Class:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# height, weight, forty yard, bench, broad\n",
    "# CB, NT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cb_data = raw_data.loc[raw_data['position'] == 'ILB']\n",
    "nt_data = raw_data.loc[raw_data['position'] == 'WR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = raw_data\n",
    "dataPlayers = []\n",
    "pos_index = []\n",
    "\n",
    "# print(type(qb_data))\n",
    "\n",
    "parameters = ['weight', 'heightinchestotal', 'broad', 'fortyyd', 'bench']\n",
    "\n",
    "cb_weight = cb_data['weight'].to_numpy()\n",
    "cb_height = cb_data['heightinchestotal'].to_numpy()\n",
    "cb_broad = cb_data['broad'].to_numpy()\n",
    "cb_forty = cb_data['fortyyd'].to_numpy()\n",
    "cb_bench = cb_data['bench'].to_numpy()\n",
    "\n",
    "nt_weight = nt_data['weight'].to_numpy()\n",
    "nt_height = nt_data['heightinchestotal'].to_numpy()\n",
    "nt_broad = nt_data['broad'].to_numpy()\n",
    "nt_forty = nt_data['fortyyd'].to_numpy()\n",
    "nt_bench = nt_data['bench'].to_numpy()\n",
    "\n",
    "for i in range(len(cb_data)):\n",
    "    dataPlayers.append([cb_weight[i], cb_height[i], cb_broad[i], cb_forty[i], cb_bench[i]])\n",
    "    pos_index.append(0)\n",
    "for i in range(len(nt_data)):\n",
    "    dataPlayers.append([nt_weight[i], nt_height[i], nt_broad[i], nt_forty[i], nt_bench[i]])\n",
    "    pos_index.append(1)\n",
    "    \n",
    "pos_index = np.array(pos_index)\n",
    "pos_cat = to_categorical(pos_index, 2)\n",
    "\n",
    "dataPlayers = np.array(dataPlayers)\n",
    "\n",
    "# print(dataQB)\n",
    "# print(pos_index)\n",
    "# print(qb_data['weight'])\n",
    "# print(qb_data['heightinchestotal'])\n",
    "# print(qb_data['broad'])\n",
    "\n",
    "print(dataPlayers)\n",
    "\n",
    "# print(dataPlayers[0])\n",
    "\n",
    "print(pos_cat.shape)\n",
    "print(dataPlayers.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units=2, input_shape=(5,), activation='softmax'))\n",
    "model.compile(Adam(lr=0.01), loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = model.fit(x=dataPlayers, y=pos_cat, batch_size=50, validation_split = 0.2, verbose=1, epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['accuracy'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['accuracy'])\n",
    "plt.title('accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(h.history['loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['loss'])\n",
    "plt.title('loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point = np.array(dataPlayers)\n",
    "\n",
    "# point = np.array([[200, 73, 10, 4.5, 20]])\n",
    "\n",
    "prediction = model.predict_classes(point)\n",
    "print(\"Predicted Class:\", prediction)\n",
    "print(\"Actual Class:\", pos_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
